# 객체 탐지

크게 물체의 분류 작업과 지역화 작업으로 나뉨

분류(classification): 물체가 어떤 종류인지, 클래스에 대한 확률값 분석

지역화(localization): 물체의 위치를 파악하는 작업을 의미, 물체가 위차한 영역의 좌표값을 예측

영역을 표현하는 2가지 방법

- Bounding Box: 객체의 영역을 사각형 형태로 표현, 위치와 크기를 파악
- Mask: 겍체의 영역을 픽셀 단위로 정확하게 분할해 표현, 각 픽셀마다 클래스 정보를 갖고 있음

객체 탐지 방법의 3가지 방법

- Bounding Box Detection: 경계 상자를 활용해 빠른 속도로 간단하게 표현 가능하지만, 사각형의 한계로 객체의 상세한 영역을 파악하기는 힘듬
- Semantic Segmentation: Mask 방식을 사용해 픽셀단위로 분할하여 섬세한 객체 검출이 가능하지만, 계산 비용이 높고 객체 간 경계에서 오분류할 가능성이 있음
- Instance Segmentation: 객체를 픽셀 단위로 분리하고, 경계 상자와 클래스 레이블을 추출. 두 방식을 모두 사용하므로 더 높은 계산 비용과 학습 데이터를 요구함

# Faster R-CNN(Towards Real-Time Object Detection with Region Proposal Networks)

전통적인 파이프라인 방식의 모델과 달리, 중간 단계에서의 처리나 변환없이 입력과 출력 사이의 관계를 직접 학습해 결과를 예측함 > 모델 구성과 훈련이 더욱 간단해지고 효율적으로 이뤄짐.

또 모델의 유연성이 뛰어나 다른 모델과의 조합을 통해 성능을 높일 수 있고 다양한 변형 모델에서도 우수한 성능을 제공

## R-CNN(Region Based Convolutional Neural Networks)

딥러닝 모델, 영역 제안(Region Proposal), 특징 추출, 서포트 벡터 머신을 활용해 객체 탐지를 수행

영역 제안: 객체 탐지를 위해 사용되는 영역 추출 알고리즘 중 하나인 선택적 탐색(Selective Search)알고리즘 사용(규칙 기반의 알고리즘으로 입력 이미지에서 객체가 있을만한 후보 영역을 생성)

후보 영역은 입력 이미지에 대한 인접한 픽셀과 비슷한 색상, 질감, 밝기, 크기 등 유사한 특징을 갖는 영역을 군집화 > 반복 > 이를 통해 군집으로 객체가 존재할 수 있는 영역을 추출

가장 우수한 영역을 선택하기 위해 비최댓값 억제(Non-Maximum Suppression, NMS)수행해 후보 영역이 실제 영역과 일치하게 학습해 영역의 위치와 크기를 조정

기존의 객체 탐지 알고리즘은 이미지를 영역별로 나눠 각 영역에 대해 객체 여부를 판단했다면,

R-CNN은 이미지 내 객체가 위치할 만한 후보 영역을 생성해 객체를 탐지

## Fast R-CNN

R-CNN의 연산량과 메모리 사용량이 많은 점과 모델 학습 단계가 분리돼 잇어 종단간 학습(End-to-End Learning)이 불가능한 성능 향상의 문제점을 개선한 더울 빠르고 정확한 물체 인식이 가능한 모델

입력 이미지를 사전 학습된 합성곱 신경망에 전달해 특징 맵을 추출, 이 특징 맵에 영역 제안 방법으로 관심 영역(Region Of Interest, ROI)를 찾음

이후 관심 영역 풀링( ROI Pooling)으로 고정된 크기의 특징 맵을 추출해 완전 연결 계층에 전달해 물체의 클래스와 위치를 예측

관심영역풀링: 관심 영역에을 잘라내 고저된 크기의 특징맵으로 변환하는 작업, 후보영역들은 다양한 크기와 비율을 갖음

특징 맵을 두 개로 나눠 하나는 클래스를 분류하고 하나는 경계 상자를 검출

## Faster R-CNN

Region Proposal Network, RPN을 사용해 관심 영역을 추출하는 방식, 앞선 방식보다 더 정확한 관심 영역 추출 가능

영역 제안 네트워크를 사용해 관심 영역을 추출하고 추출된 관심 영역을 관심 영역 풀링을 통해 고정된 크기의 특징 맵으로 변환 후, 이를 분류기와 회귀기 에 입력해 객체를 검출한다.

영역 제안 네트워크에서 관심 영역 추출과 특징 맵 변환을 동시에 수행해 모델의 매개변수를 공유해 더 경량화된 모델 구성

### 영역 제안 네트워크

R-CNN처럼 모든 영역에서 특징 벡터를 추출하는 것이 아닌, 갬체 탐지를 위한 특징 추출과 경계 상자 위치 추정을 위한 영역 제안 방식을 합친 구조

입력 이미지에서 객체의 관심 영역을 추출하는 네트워크이고 GPU 사용이 가능해 더 빠른처리가 가능

입력 받은 특징 맵을 일정한 크기의 윈도 영역을 이동해 가면서 중간 층에 전달하고 합성곱 연산을 수행해 생성된 벡터를 물체를 판별하는 박스 분류 계층과 영역의 좌표를 생성하는 박스 회귀 계층에 전달 슬라이딩 원도는 일정한 크기의 그리드로 분할하고 이미지의 크기를 그리드 크기로 나눔

### 앵커 박스

객체의 위치와 크기를 예측하기 위해 사용되는 사각형 영역, 일반적으로 다양한 종류의 객체를 고려해 여러 개의 크기와 종횡비로 정의됨

128, 256, 512 크기로 맞춰저 있고 1:1, 2:1, 1:2 비율을 사용

### 박스 분류

앵커 박스에 객체가 존재하는지 또는 존재하지 않는 점수를 계산, 한개의 슬라이딩 윈도는 9개의 앵커 박스를 가지고 있어 총 18개가 생성됨

### 박스 회귀

앵커 박스로 크기와 위치를 예측했다면 박스 회귀를 통해 경ㄱ예 상자의 크기와 위치를 조정해야함.

고정적인 비율과 그리드를 통해 특징 맵으로 변환했으므로 예측값은 정확하지 않음.

따라서 R-CNN 처럼 박스 회기를 통해 경계 상자를 조정하는 작업이 진행됨.

### 관심 영역 선별

영역 제안 넽워크를 통해 앵커 박스의 객체 여부와 앵커 박스의 위치와 크기를 계산, 앵커 박스는 특징 맵의 슬라이딩 윈도마다 생성되 특징 맵의 크기가 커질수록 애커 박스의 개수 증가, 선별 방법으로 관심영역을 선택해 학습 및 추론속도가 느려지는 것을 방지

# SSD(Single Shot MultiBox Detector) 555

이미지 내의 객체를 감지하기 위해 이미지의 다양한 위치에서 여러 개의 경계 상자를 예측, Multi-box Detection

멀티 박스 탐지: 이미지에서 사전에 정의된 경계 상자를 설정하고 그것을 Positive와 Negative으로 레이블링해 학습

SSD는 R-CNN과 다르게 1-stage로 처리 속도가 빠르다는 장점, 한번의 순전파로 객체 감지를 수행해 처리 속도가 빠름

특징 추출 모델은 이미지넷으로 사전 학습된 분류 모델에 여러 계층을 추가한 구조로 다양한 크기의 특징맵을 추출해 객체의 다양한 크기를 인식할 수 있고 이런 구조로 영역 제안 결과가 필요없어 병목 현상이 사라져 빠른 추론이 가능해짐

## 멀티 스케일 특징 맵

SSD에서 다양한 크기의 객체를 인시갛기 위해 다양한 크기의 특징 맵을 사용하는 구조로 특징 추출 모델의 앞부분에서 추출한 특징 맵은 작은 객체를 인식할 때 사용하고 뒷부분에서 추출한 특징 맵은 큰 객체를 인식 

## 기본 박스(Default Box)

앵커 박스와 유사한 개념, 차이점은 서로 다른 크기의 특징 맵에 적용한다는 것

특징 맵의 크기가 작을 수록 기본 박스를 크게 설정해 큰 객체를 인식할 수 있고 반대로 특징 맵이 작을 수록 기본 박스는 작게 설정

입력 이미지의 크기와 특징 맵의 크기를 고려해 초기 기본 박스의 크기를 설정, 이후 다양한 스케일 값을 적용해 기본 박스의 크기를 조정

## 모델 학습 과정

Faster R-CNN과 동일하게 박스 분류와 박스 회귀에 대한 손실 함수를 계산

SSD는 영역 제안 네트워크가 없기에 배경 영역을 미리 선별할 수 없고 모델의 출력값 중 대부분이 배경 영역을 차지함 

그러므로 모든 출력값에 대해 학습을 수행하면 배경 역역과 객체 영역 간의 클래스 불균형이 발생해 원활한 학습이 진행되지 않음

이를 해결하기 위해 Hard Negative Mining기법 사용, 모델이 학습하기 어려운 샘플을 선택해 추가 학습을 진행하는 기법

SSD에서는 객체의 영역(Positive)과 배경의 영역(Negative)

# FCN(Fully Convolutional Network)

전통적인 합성곱 신경망의 한계를 극복하고자 고안된 모델, 특징 추출후 완전 연결 계층에서 이미지 분류를 수행하는 모델은 이미지 분류와 객체 탐지와 같은 작업에서는 높은 성능을 보엿지만 의미론적 분할과 같은 작업에서는 높은 성능을 기대하기 어려웠음

의미론적 분할: 이미지에서 각 픽셀에 해당하는 클래스를 구분하고 인스턴스및 배경을 분할하는 것 이미지 내의 모든 객체 및 구조물의 경계를 정확하게 실벽하고 각 픽셀을 이러한 객체 또는 구조물에 할당함으로써 수행되는데, 전통적인 합성곱 신경망 모델은 완전 연결 계층을 사용하기 때문에 위치 정보가 손실되 픽셀의 위치 정보를 파악하기 어려웟음.

FCN은 위치 정보를 유지하면서 클래스 단위의 특징 맵을 추출하기 위해 완전 연결 계층을 제거하고 공간 정보를 포함하는 합성곱 계층으로 대체함 > 구조가 간단해져 의미론적 분할 문제 해결에 있어 보다 정교하고 우수한 성능을 보임

## 업샘플링(Upsampling)

계층을 통과할수록 특징 맵의 크기가 줄어 업샘플링을 통해 특징맵의 입력 크기와 동일하게 확장하는 과정을 추가, 이를 통해 FCN 은 이볅 이미지의 공간 정보를 보존하면서 객체를 픽셀 수준으로 정확하게 분할할 수 있음

보간 방법의 2가지 기법

- 이중 선형 보간법(Bilinear Interpolation)

이웃하는 4개의 픽셀 값에 대한 가중치를 계산, 선형 보간법을여러 번 적용해 구할 수 있음 

계산이 간단하고 빠르지만, 높은 정확도를 요구하는 이미지 확대 작업에는 적합하지 않음

- 전치 합성곱(Transposed Convloution)

입력에 패딩을 넢어 입력의 크기보다 큰 출력값을 생성하는 합성곱 연산, 간격과 커널의 크기를 설정해 출력 크기를 조절할 수 있음

학습이 가능해 일반적인 보간법보다 더 나은 성능을 보일 수 있지만 크기가 클수록 연산량이 기하급수적으로 증가해 최근엔 사용하지 않는 경향이 있음 ( 높은 계산 비용)


# Mask R-CNN

기존 Faster R-CNN의 문제점은 객체의 대략적인 위치를 검출할 수 있지만, 정확하게 검출하기 어려움 객체를 고정된 크기로 변환하고 관심 영역 풀링을 수행하는 과정에서 발생하는 손실로 인하여 공간적 어긋남을 초래함

이런 문제를 개선하기 위해 Mask R-CNN 관심 영역 풀링대신 관심 영역 정렬이라는 방법을 사용해 어긋남을 최소화 함

또 Faster R-CNN은 박스 분류와 박스 회귀만 수행해 객체의 위치와 종류만 탐지함, Mask R-CNN은 이두가지 이외에도 마스크 영역을 추가해 각 객체에 대한 세그멘테이션 마스크를 예측할 수 있음

이를 통해서 객체의 정확한 모양을 파악할 수 있게 됐고, 객체 분류 및 인식 성능이 크게 향상됨

Mask R-CNN은 특징 피라미드 네트워크, 영역 제안 네트워크, 관심 영역 정렬, 분류 및 분할로 수행됨

## 특징 피라미드 네트워크(Feature Pyramid Network, FPN)

다양한 비율의 객체를 탐지하기 위해 트징 맵을 여러 레벨로 구성하는 방법

분류 모델은 입력 이미지를 여러 계층에 걸쳐 점점 다운샘플링을 하면서 특징 맵을 생성 이때, 상위 계층으로 갈수록 수용 영역이 커지고 특징 맵의 크기가 줄어듬 > 최상위 계층에서 얻은 특징 맵은 고수준의 의미적으론 정보를 갖지만 공간적인 정보는 손실되고 해상도는 낮아짐 > 작은 객체나 세부적이 모양을 구분하기 어렵게 만듬

이런 문제를 해결하기 위해 FPN 사용, 특징 맵의 하양식 경로와 상향식 경로를 결합해 각 스테이지의 특징 맵이 공간적인 정보와 의미론적인 정보를 가질 수 있게 함

하양식 경로는 입력 이미지를 다운샘플링하면서 특징 맵을 생성하는 과정으로, 순전파를 진행하면서 마지막 계층을 포함한 여러 계층에서 특징 맵을 추출하는 방법

FPN는 이런 트레이드 오프를 극복하기 위해 상위 계층의 특징 맵을 업샘플링하고 하위 계층의 특징 맵과 결합해 각 계층의 특징 맵 이 공간적인 정보와 의미론적 정보를 모주 갖게 함

## 관심 영역 정렬(ROI Align)

합성곱 연산으로 생성된 특징 맵 관심 영역 사이의 공간적 어긋남을 최소화하기 위한 방법

관심 영역 풀링과 비슷한 개념이지만, 관심 영역 풀링은 좌표를 반올림 하는 등의 근사 방법으로 인해 정보의 손실이 발생함(소수점 영역에 대한 정보)

## 마스크 분류기

관심 영역 정렬을 통해 생성된 특징 맵에 마스크 분류기를 통과시켜 segmentation mask를 예측

마스크 분류기는 각각의 관심 영역에 대해 클래스별로 이진 마스크를 출력함

마스크 분류기는 박스 분류나 회긔에 영향을 주지 않고 관심 영역 정렬을 통해 생성된 특징 맵과 관심 영역을 활용해 합성곱 신경망을 적용하거나 마스크 분류기를 더 세분화하기 위해  FCN 구조를 사용

마스크 영역의 해삳ㅇ도를 높이기 위해 보간법을 통해 특징 맵의 크기를 확장하며, 1x1 합성곱 연산으로 특징 맵의 차원 클래스 개수에 맞게 변환함

최상위 계층에서 반환되는 마스크의 채널에 해당하는 값은 해당 클래스에 대한 객체의 마스크가 됨

이때 시그모이드 함수를 통해 각 채널의 값이 0~1값을 갖고, 1에 가까울수록 객체의 영역이 됨

이후 원본 이미지의 크기에 맞기 비율을 조정하면 픽셀 수준의 세분화된 마스크가 생성

### 마스크 손실 함수

학습 과정은 Faster R-CNN의 과정과 유사하지만 마스크 분류기가 추가되 마스크 검출에 대한 손실 함수가 추가됨

### 마스크 영역 시각화

경계 상자뿐만 아니라 마스크 데이터도 필요한데 분할 카스크 데이터는 객체의 마스크를 폴리곤 데이터로 제공, 필리곤은 경계 상자 좌표와 달리 다양한 형태의 모양을 표현할 수 있어 객체 영역을 더 상세하게 표현할 수 있음( 다각형을 구성하는 각 꼭짖점의 좌표로 제공) , 하나의 폴리곤으로 표현할 수 없다면 여러 개의 폴리곤을 리스트로 묶어 표현
모델 학습에 사용할 때는 이진 마스크 형태로 변환해서 입력해야 함

# YOLO(You Only Look Once)

1-stage 구조 모델로 실시간 객체 탐지 모델, 이전 객체 탐지 방법들은 분류기를 재사용해 탐지를 수행했지만, YOLO는 객체 탐지를 공간적으로 분리된 경계 상자와 관련된 클래스 클래스 확률에 대한 회귀 문제로 바라봄

실시간 객체 감지를 수행할 수 있고, 높은 정확도와 빠른 처리 속도를 보장해 객체 검출 작업에서 널리 사용됨

## YOLOv1

단순한 구조로 객체를 빠르게 탐지할 수 있다는 큰 장점, 1-stage구조로 영역 제안 네트워크를 필요하지 않음

다중 특징 맵을 사용하지 않고 한 방향으로 순차적으로 진행하는 단일 특징맵을 통해 검출을 수행, 샐마다 2개의 경계상자를 예측

클래스 예측이 겹치지 않도록 그리드마다 하나의 클래스만 예측하므로 겹쳐 있는 객체를 예측하는 것은 어려움, 또 경계 상자의 수가 적기 때문에 다양한 형태의 객체를 검출하는 데는 불리한 명이 있음

## YOLOv2

v1과 비교해 앵커 박스를 사용해 더 많은 수의 경계 상자를 예측하고 백본 모델 변경 및 배치 정규화를 적용해 모델의 성능을 개선시킴

완전 연결 계층을 제거해 연산량을 줄임, 기존 객체 검출 모델들은 앵커 박스의 크기와 비율을 임의의 값으로 설정함, 하지만 YOLOv2는 K-평균 군집화 알고리즘을 사용해 앵커 박스의 크기와 비율을 결정해 학습 데이터세트의 정답 박스 분포를 반영할 수 있었고 이를 통해 성능을 개선할 수 있었다.

또 작은 물체에 대한 검출 성능을 향상시키기 위해 특징 맵을 4개로 분할하고 마지막 차원을 기준으로 재결합하는 방법을 사용 이를 통해 한방향으로만 순차적으로 진행하는 구조를 유지하면서 작은 물체를 검출하는 성능을 개선함

## YOLOv3

다중 특징 맵, 잔차 연결 등의 기법을 사용해 모델의 성능을 개선, 백본 모델도 더 깊은 DarkNet-53

ResNet 모델의 잔차 연결 기법을 사용해 이미지의 특징 추출 성능을 향상

v2의 하나의 출력 특징 맵만 사용하는 것은 여전히 작은 객체 검출에 불리해 v3에서는 다중 특징 맵을 사용, 다양한 스케일의 특징 맵에서 객체를 인식할수 있어 다양한 크기의 객체를 검출하는데 유리

다중 특징 맵을 사용하기 위해 여러 번의 업샘플링 작업을 거쳐 구성된 구조로, 순전파가 세 가지 방향으로 진행돼 세 개의 출력 텐서가 생성

- 첫 번째 출력 텐서는 특징 맵의 크기가 작아 주로 큰 객체를 검출하는데 사용, 세 번째 출력 텐서는 특징 맵의 크기를 업샘플링해 그리드 개수가 많아져 작은 객체를 검출하기에 유리

업샘플링 작업으로 손실되는 정보들은 잔차 연결을 통해 보완함, 이를 통해 모델의 깊이와 출력 특징 맵의 스케일을 확장하면서도 뛰어난 성능을 유지

## YOLOv4/YOLOv5

v4는 다중 특징 맵을 사용할 때 객체의 세부 정보를 잃지 않도록 업샘플링 과정을 개선 이를 위해 경로 집합 네트워크(Path-Aggregation Network,PAN) 구조를 도입

PAN은 FPN과 유사하지만, 특징 맵 간의 결합을 덧셈이 아닌 채널 단위로 수행해 더욱 효율적으로 정보를 전달함. PAN은 Mask R-CNN에서도 사용되는 기술로 높은 검출 정확도와 성능을 보장

v4에서 모델 구조만 개선한 것이 아닌 새로운 데이터 증강 기법을 도입해 성능을 향상시킴, 그중 모자이크 합성은 대표적인 기법은 v4 모델 성능 향상에 크게 기여함

모자이크 합성은 학습 이지미 네 개씩 모아서 바둑판 형식으로 붙여, 한번에 학습하는 기법, 다양한 크기와 위치에 대한 객체 인식 능력을 강화하고 데이터의 다양성을 높이는 효과를 얻을 수 있음

또 이를 통해 이미지의 크기가 줄어들어 작은 객체 데이터를 효과적으로 수집할 수 있고 같은 객체를 다양한 스케일로 학습할 수 있기 때문에 크기 변화에 더 강인한 학습 효과를 기대

v5는v4의 모델 구조를유지하고 파이토치 라이브러리로 이식해 세부 사항 조정, 모델을 최적화해 인석 성능과 추론 속도 개선, 구조적으론 큰 변화가 없으며, 모델 크기에 따라 N(Nano), S(Small), M(Medium), L(Large), X(Extra Large) 버전으로 제공 점진적으로 높은 정확도를 제공하지만 크기가 커지면 학습 및 추론 시간이 더 길어진다

## YOLOv6/YOLOv7

v6은 백본 모델에 RepBlock을 적용해 인식 성능과 추론 속도를 개선한 모델로, 매개변수 재정의라는 기법을 통해서 설계된 네트워크로 RepVGG 구조를 참고해 설계

계층의 가중치를 재구성해 새로운 계층으로 치환하는 방법으로 수행, 일반적인 합성곱 모델은 학습과 추론에 적용된는 모델 구조가 동일 하지만 RepBlock을 적용한 모델은 모델 학습 시 여러 방향으로 순전파가 진행되며, 모델 추론 시 한 방향으로만 순전파가 진행

RepBlock은 여러 개의 분기로 1x1 합성곱 계층과 항등 매핑 계층을 사용해 ResNet의 잔차 연결과 유사한 방식으로 모델을 학습함, 이후 추론 시 에는 같은 위치의 합성곱 계층을 합성해 새로운 3 x 3 합성곱 계층으로 변환한 후 한 방향으로 순전파를 진행 > 모델의 성능과 추론 속도를 개선하고, 앵커 박스를 사용하지 않아 불피룡한 연산 과정을 제거

앵커 프리 방식은 출력 특징 맵에서 그리드 단위로 객체를 인식하는 차원 수가 작고 모든 앤커 박스에 대한 후처리 과정이 사라지므로 연산량이 줄어듬

v6는 다중 스케일 구조이므로 한영역의 객체가 겹쳐 있더라도 다른 스케일의 특징 맵에서 객체를 추출할 수 있어 겹쳐진 객체도 정확하게 인식할 수 있음

v7은 RepBlock을 개선한 RepConvN을 사용, 기존의 문제인 항등 매핑 계층으로 인해 순전파가 중복되서 RepConvN으로 항등 매핑 계층을 제거해 순전파 중복 문제를 해결

RepConv 잔차 연결의 연결선을 보면 항등 매핑으로 인해 첫 번재 특징 맵의 정보에 대해 덧셈 연산이 두 번 수행되는데 RepConvN은 잔차 연결은 중복이 발생하지 않고 연산이 한 번만 수행되는걸 볼 수 있다.

v7은 학습 방법을 변경해 모델의 최종 출력인 주 출력(Lead Head)과 학습을 보조하는 보조출력(Auxiliary Head)을 따로 구성. 보조 출력 학습 과정에서는 주 출력 값과 정답 값을 기반으로 생성한 약한 레이블로 재학습 이런 방법으로 모델을 구성하면, 주 출력에서는 최대한 근사할 수 있는 강한 학습이 수행되고, 반대로  보조 출력에서는 약한 학습이 진행됨

## YOLOv8 실습

v8은 v5의 구조를 개선한 모델로 v6처럼 앵커 프리 구조를 사용해 추론 속도를 향상 시킴. 또 모자이크 합성 이미지로 학습을 수행하는 경우 성능이 저하되는 문제가 발생하는데, v8은 10에폭만 적용해 과대적합을 방지하고 성능을 개선시킴

울트라틱스(ultralytics)의 v8은 포즈 추정을 비롯해 검출, 세그멘테이션, 분류 모델을 지원