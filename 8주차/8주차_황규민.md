이미지 처리를 자연어 처리 방식처럼 분류해 보려는 시도에 의 해 탄생

CNN 모델의 합성곱 계층 방법을 사용하지 않고 트렌스포머 모델의 셀프 어텐션을 적용

- 전체 이미지를 한 번에 처리하는 방식
- 이미지 패치가 왼쪽에서 오른쪽, 위에서 아래의 방향으로 순차적 입력되 2차운적 구조의 이미지 특성을 온전히 반영한다고 할 수 없음
    - 이런 문제를 해결하기 위해 물체의 크기나 해상도를 계층적으로 학습하는 모델
        - 스윈 트랜스포머(Swin Transformer)
        - CvT(Convolutional Vision Transformer)

스윈 트랜스포머는 로컬 윈도를 활용해 각 계층의 어텐션이 되는 패치의 크기와 개수를 다양하게 구성해 이미지의 특징을 학습하고 ViT 구조와 비교할 때 기존 셀프 어텐션을 로컬 윈도 안에 대한 어텐션, 로컬 윈도간의 어텐션으로 수행하여 이미지 특징을 계층적으로 학습시킴, 어텐션 함수는 상대적위치 편향을 반영하여 어텐션 값 자체에 위치적 정보를 포함

CvT는 기존 합성곱 연산 과정을 ViT에 적용한 모델, 저수준 특징과 고수준 특징을 계층적으로 반영하고 어텐션 연산과정에서 키(key)와 값(value)을 기존 특징 벡터보다 축소해 계산 복잡도를 감소시킴

# ViT(Vision Transformer)

이미지가 격자로 작은 단위의 이미지 패치로 나뉘어 순차적으로 입력됨, 패치는 왼쪽에서 오른쪽, 위에서 아래로 표현된 시퀀셜 배열을 가정

## 합성곱 모델과 ViT 모델 비교

두 모델은 이미지 특징을 잘 표현하는 임베딩을 만들고자 하는 목적은 같지만, 합성곱 신경망의 임베딩은 이미지 패치 중 일부만 선택해 학습하고, 이를 통해 이미지 전체의 특징을 추출

ViT 임베딩은 이미지를 작은 패치들로 나눠 각 패치간의 상관관계를 학습, 이를 위해 셀프 어텐션 방법을 사용해 모든 이미지 패치가 서로에게 주는 영향을 고려해 이미지의 전체 특징을 추출

이런 이유로 ViT는 모든 이미지 패치가 학습에 고나여해 높은 수준의 이미지 표현을 제공

합성곱 신경망은 좁은 수용 영역(Receptive Field, RF)을 가져 전체 이미지를 표현하는데 수 많은 계층이 필요하지만, ViT 모델은 어텐션 거리(Attention Distance)를 계산해 오직 한 개의 레이어로 전체 이미지 정보를 쉽게 표현할 수 있음 또 픽셀 단위로 처리하는 합성곱과 달리 패치 단위로 이미지를 처리해 더 작은 모델로도 높은 성능을 얻을 수 있음

ViT 모델은 입력 이미지의 크기가 고정되어 있어 크기가 다른 이미지를 처리하려면 이미지 크기를 맞추는 전처리가 필요하고, 합성공 신경망이 이미지의 공간적 위치정보를 고려하는데 비해 ViT는 패치간의 상대적인 위치 정보만 고려해 이미지 변환에 취약할 수 있음

## ViT의 귀납적 편향

귀납적 편향(Inductive Bias)는 일반화 성능 향상을 위한 모델의 가정(Assumption)을 의미

합성곱 신경망은 지역적인 특징을 강조한는 특성을 갖고 있기 때문에 이미지데이터에서 좋은 성능을 발휘하고 시퀀셜 편향을 가진 순환 신경망은 시계열 데이터에서 좋은 성능을 발휘한다. 하지만 이런특정 관계 편향이 강할수록, 다른 다양한 관계를 표현하기 어려워 귀납적 편향이 약한 모델을 선호하게 되는데 ViT 모델은 입력 데이터의 다양한 쿼리 키 값 의 임베딩 형태로 일반화된 관계를 학습하기 때문에 귀납적 편향이 거의 없고, 대용량 데이터에 대해서 이미지 특징들의 관계를 잘 학습하는 모델로 알려짐

귀납적 편향은 해당 모델이 가지는 구조와 매개변수들이 데이터에 적합한 가정을 하고 있음을 나타냄

## ViT 모델

입력 이미지를 트랜스포머 구조에 맞기 일정한 크기의 패치로 나눠 각 패치를 벡터 형태로 변환하는 패치 임베딩(Patch Embedding)과 각 패치와의 관계를 학습하는 인코더(Encoder)계층으로 구성

패치 임베딩과 인코더 계층을 통해 이미지의 특징을 추출하고 분류나 회귀와 같은 작업에 맞는 출려값으로 변환해 사용

## 패치 임베딩(Patch Embedding)

입력 이미지를 작은 패치로 분할하는 과정을 말함. 이를 위해 크기를 맞추는 전처리 수행 (정방향 크기) 후 패치 크기로 분할해 시퀀셜 배열 생성 (이때 합성곱 신경망의 계층 활용)

패치 임베딩을 위해 커널 크기(패치 크기)와 간격(폭)을 설정(하이퍼파라미터)

$patch\space size= \dfrac{image\space size-kernel\space size}{stride}$ 패치의 배열 순서 왼쪽 > 오른쪽, 위 > 아래

배열의 가장 왼족에 분류 토큰(Special Classification Token, CLS) 추가

- 전체 이미지를 대표하는 벡터로 특정 문제를 예측하는데 사용

위치 임베딩(Position Embedding)을 사용해 인접 패치간의 관계 학습, 위치 정보를 임베딩 벡터로 변환하고 기존 이미지 패치 벡터들과 더함

## 인코더 계층

패치를 변환 후 인코더 계층에 입력ㅇ로 전달해 다양한 쿼리, 키, 값 임베딩의 관계를 학습(멀티헤드 어텐션의 학습 과정과 동일)

N개의 인코더 레이어를 반복적으로 적용한 후, 마지막 레이어에서는 분류 토큰이라고 불리는 특별한 패치의 특징 벡터를 추출, 이 분류 토큰 벡터는 이미지 데이터를 잘 표현하는 특징 벡터로 간주되고 이후에 다양한 이미지 분류 및 거색 문제를 해결하는데 사용 (이미지 전체를 학습과정에 사용하는 것이 아닌 분류 토큰 벡터만 사용) > 분류 토큰 벡터를 순방향 신경망에 연결하고 분류하는 방법으로 학습

## Swin Transformer

대규모 비전 인식 모델, 기존 트랜스포머를 기반으로 하는 모델의 공통적 문제점은 고정된 패치 크기로 세밀한 예측을 필요로 하는 의미론적 분할과 같은 작업에 적합하지 않다는 점 또, 셀프 어텐션은 입력 이미지 크기에 대한 2차(Quadratic) 계산 복잡도를 가져 고해상도 이미지를 처리하기 어려웠음

이런 문제를 극복하기 위해 계층적 특징 맵을 구성해 1차 계싼 복잡도를 갖는 스윈 트랜스포머 제안

구조는 이미지 분류, 객체 감지, 영상 분할과 같은 인식 작업에서 강력한 성능을 내며, 트랜스포머 구조보다 이미지특성을 잘 표현할 수 있음

시프트 윈도(Shifted Window)라는 기수을 이용해 입력 이미지를 일정한 크기 패치로 분할하고 이 패치를 쌓아 윈도를 구성, 구성된 원도 영역만 셀프 어텐션을 계산

이는 기존의 트랜스포머 모델과 다르게 패치를 겹쳐 더 큰 효율성을 제공, 또 계층마다 어텐션이 수행되는 패치의 크기와 개수를 계층적으로 적용해 처리하므로 높은 해상도와 다양한 크기를 개치 객체를 효율적으로 처리할 수 있음

객체 탐지나 객체 분할 등과 같은 작어벵서 백본 모델로 사용

## ViT와 스윈 트랜스포머 차이

ViT는 획일적인 패치 크기와 위치에 대한 제약 때문에 다양한 이미지 크기와 종횡비를 가진 데이터 세트에 대해서 적용이 어려웠고 또 패치 단위로 입력 받기 때문에 이미지의 공간 종보가 완전히 보존지 않음

이미지의 패치 수가 증가하면 학습 데이터의 크기도 커지기 때문에 모델 학습에 필요한 계산량이 증가, 이로 인해 대규모 데이터세트에서 학습에 필요한 컴퓨팅 자원을 많이 사용하게 되는 단점이 있음

이 한계점을 보완하기 위해 로컬 윈도(Local Window)를 활용해 물체 크기나 해상도를 계층적으로 학습함.(입력 이미지를 처리하기 위해 사용되는 고정 크기의 작은 윈도)

이런 로컬 윈도를 이동시키는 시프트 윈도 기술을 도입해 입력 이미지를 일정한 크기의 패치로 분할하고, 특징 맵을 이동시켜 다음 계층에 사용함으로써 패치의 위치를 더 유연하게 다룸, 이를 통해 ViT보다 더 높은 정확도와 더 적은 매개변수 가지면서도 더 넓은 범위의 이미지 크기와 종회비를 다룸

- 네트워크 구조 비교

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/6142e56d-087a-49b7-b8e7-e7461c358ff7/image.png)

회색 격자는 패치, 빨간 격자는 로컬 윈도

ViT의 네트워크는 계층마다 전체 이미지 안에 어텐션이 수행되는 패치와 크기가 동일하지만, 스윈은 로컬 윈도를 통해 계층마다 어텐션이 되는 패치의 크기와 개수를 계층적으로 다양하게 적용

입력 패치의 로컬 윈도를 통해 계층적으로 접근하고 스프트 윈도로 로컬 윈도를 이동해 가면서 인접 패치 간 정보를 계산

이런 계층적 접근 방식은 로컬 윈도가 각 패치의 세부 정보에 집중하게 되고, 시프트 윈도를 통해 전역 특징을 확인할 수 있으므로 고해상도 이미지를 효율적으로 처리

## 스윈 트랜스포머 모델 구조

이미지를 패치 파티션으로 구분 후, 선형 임베딩, 스윈트랜스포머 블록, 패치 병합, 연산이 반복적으로 수행됨

먼저 입력 이미지를 일정한 크기의 패치로 분할하고, 각 패치에 대해 선형 임베딩을 수행, 각 패치는 고정된 차원의 벡터로 변환

분할된 패치들을 기반으로 스윈트랜스포머 블록 구성, 이 블록은 어텐션 계층, 계층 정규화, 다층 퍼셈트론등을 포함해 패치 간 상호작용을 수행

마지막으로 패치를 병합해 전체 이미지에 대한 분류를 수행, 분할된 패치들을 순차적으로 합치면서 이미지의 전체적인  정보를 추출하는 방식 사용

구조는 일반적으로 4개의 스테이지로 구성돼 있으며, 각 스테이지는 서로 다른 해상도와 패치 크기를 갖음.

패치 병합은 모델의 매개변수를 줄이기 위해 이미지 텐서를[C, H, W] > [2C, H/2, W/2]로 재정렬해 저차원 임베딩을 수행

트랜스포머 블록은 윈도 격자 안에 있는 패치(내부의 관계), 윈도 격자 간의 관계를 학습하는 두 가지 어텐션 모듈로 이뤄짐

### 패치 파티션(Patch Partition) / 패치 병합(Patch Merging)

- 패치 파티션
    
    입력 이미지를 작은 사각형 패치로 분할해 처리하는 방식을 의미, 분할 된 패치는 트랜스포머 계층의 입력으로 사용되며, 입력 이미지의 공간 정보를 보존하고 트랜스포머 계층에 대한 계산 효율성을 높임
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/023996fe-f284-4fcc-a5e1-1bf30d3cd62a/image.png)
    
    일반적인 이미지 텐션 [C, H, W] 구조를 갖음
    
- 패치 병합
    
    인접한 패치들의 정보를 저차원으로 축소하는 과정을 의미, 모델의 매개변수의 수를 줄이기 위해 이미지 패치 텐서를 저차원으로 임베딩
    
- 스윈 트랜스포머 블록
    
    패치 파티션 이후 네 개의 스테이지 안에서 반복 적용되, 선형 임벵딩 또는 패치 병합 이후에 수행
    
    계층 정규화, W-MSA,MLP,SW-MSA등으로 구성됨
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/74d8415c-4131-40f5-98cc-60003a421c6a/image.png)
    
    기존 트랜스포머 모델에서 사용하던 MSA 방식이 아닌 W-MSA와 SW-MSA로 구성되며 순차적으로 수행
    
    W-MSA란 로컬 뒨도를 사용하는 멂티 헤드 셀프 어텐션으로, 입력 특징 맵을 중첩되지 않게 나눠 각 윈도에서 독립적으로 셀프 어텐션을 수행
    
    W-MSA는 이미지에서 일정한 크기의 윈도 영역을 설정하고, 해당 영역 내 픽셀 간의 어텐션을 계산, 이를 통해 이미지 내의 전체적인 어텐션을 수행하고, 특정 위치에 대한 정보를 추출함. 또 각 윈도 내 지역적인 특징을 분석할 수 있으며, 전체 입력에 대한 셀프 어텐션 비용을 2차 계산복잡도에서 1차로 줄임
    
    이것은 연산량은 대폭 감소했지만, 윈도 내부의 이미지 패치영역에만 셀프 언텐션을 수행한다는 단점이 있고 이를 보완하기 위해 SW-MSA는 윈도 사이의 연결성을 구축해 윈도 간의 관계성 정보를 추출, 윈도를 가로 또는 세로 방향으로 이동한 후, 인접한 윈도 간의 셀프 어텐션을 계산
    
    - 두 가지의 어텐션 영역 비교
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/3c365d3d-2bf8-4bb7-a9f5-2ae3469ae1e7/image.png)
        
    
    W-MSA 방식은 로컬 윈도 빨간색 영역 안에서 패치 간의 셀프 어텐션 연산을 수행하는 방식, 이때 로컬 윈도가 이동하면서 각 윈도에서 연산을 수행하므로 계산량이 많아지는 것 처럼 보일 수 있지만 효율적인 배치 계산(Effieient Batch Computation)을 통해 연산량을 감소시킴 
    
    - 연산을 수행하는 과정에서 배치 축을 사용해 연산 속도가 빨라짐
    
    SW-MSA방식은 로컬 윈도 간의 셀프 어텐션을 수행하기 위해 W-MSA에서 사용된 로컬 윈도 개수가 많아 더 많은 셀프 어텐션 연산을 요구, 이를 해결하기 위해 Cyclic SHift와 Attention Mask사용
    
    - 순환 시프트를 활용한 SW-MSA 어텐션 계산 과정
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/5ece1c26-ad88-41dc-8ab2-3c072a4e28f9/image.png)
        
    
    로컬 윈도가 이동할 때 이동한 위치의 정보를 이전 위치에서 가져오는 것을 말하고, 로컬윈도 사이즈 M보다 작은 M/2 만큼 로컬 윈도들을 이동
    
    이때, 이동된 위치에서 연산을 수행하지 않도록 어텐션 마스크를 사용해 방지, 로컬 윈도가 이동한 위치에서 연산을 수행하지 않게 하는 역활
    
    마지막으로 순환 시프트 단계에서 셀프어텐션을 수행한 다음 역순환 시프트(Reverse Cyclic Shift)를 사용해 원래 로컬 윈도 구조로 복원 > 로컬 윈도 간의 셀프 어텐션 연산을 효율적으로 수행
    
    - 어텐션 마스크를 활용한 각 윈도 파티션의 어텐션을 구하는 방법
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/cf82b351-d39d-4605-b654-5491100b022e/image.png)
        
    
    SW-MSA 방식에서 순환시프트와 함께 어텐션 마스크를 사용해 로컬 윈도 간의 셀프 어텐션 연산을 효율적으로 수행함 이때, 어텐션 마스크를 사용하면 원래 총 9개의 윈도 파티션에 대해 9번의 셀프 어텐션 값을 구해야 했지만, 4개의 윈도 파티션에 대해 4개의셀프 어텐션 값만으로 모든 로컬 윈도 간의 셀프 어텐션 값을 계산 할 수 있음. 이는 어텐션 마스크가 순환 시프트를 토해 이동된 윈도에 대한 정보를 보존하면서도, 불필요한 연산을 줄이고 효울적인 계산을 가능하게 한다는 장점을 가짐
    
    기존 ViT와 다른 점은 셀프 어텐션에서 상대적 위치 편향을 고려하는 것, 로컬 윈도 안에 있는 패치 간의 상대적인 거리를 임베딩하는 목적을 갖음.
    
    - 편향 계산 과정
        
        ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/dad4d041-64d5-4dd8-a635-dffe1c85e593/image.png)
        
    
    패치를 1~4로 가정하면 패치 간의 상대적인 거리는 x, y축 2가지 방식으로 표기 가능
    
    - 실제 코드중(매개변수)
    
    window_size는 여러 개의 이미지 패치를 포함하는 격자의 크기를 의미하며 윈도 내외부의 패치를 구분해 주는 역활을 함
    

# CvT(Convolutional Vision Transformer)

합성곱 신경망 구조에 활용하는 계층형 구조 ViT를 적용한 모델

ViT의 셀프 어텐션은 이미지 정보를 바탕으로 각 패치 간의 관계를 학습하지만, 모든 패치에 대해 동일한 크기와 간격을 사용해 이미지의 물체 크기나 해상도를 계층적으로 학습하기 어려움

이를 CvT는 합성곱 신경망에서 사용하는 계층적 구조를 ViT에 적용해 이미지의 지역 특징과 전역 특징을 모두 활용해 비교적 적은 수의 매개변수로 높은 성능을 보임

합성곱 계층의 지역 특징을 추출하고 ViT의 셀프 어텐션 계층으로 전역 특징을 결합해 이미지를 처리

그럼으로 스윈 보다 더 적은 수의 매개변수로 비슷한 수준의 성능을 보임

- CvT 모델의 계층적 특징

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/b467f7c8-a8f4-4cec-bb37-bc8334258de2/image.png)

얼굴 이미지가 CvT 모델의 입력으로 사용된다면 저수준 계층에서 선 또는 점에 대한 특징을 표현, 중간 수준에서는 눈이나 귀와 같은 특징을 표현, 고수준에서는 얼굴 구조에 대한 특징을 표현함 그러므로 CvT의 계층형 구조는 물체의 크기나 해상도를 더 잘 표현한다

ViT는 이미지를 패치 단위로 분활해 사용하는데 이때 패치를 겹치지 않게 처리해 모델이 이미지의 전체 정보를 학습

CvT는 이미지를 처리하기 전에 합성곱 연산을 통해 특징 맵을 추출. 이를 통해 유의미한 패턴을 추출하고 일정한 크기의 패치로 나눠 트랜스포머 모델의 입력으로 사용함 입력되는 패치들은 겹쳐 학습

그럼으로 ViT는 패치 임베딩과 선형 임베딩을 사용하지만, CvT 모델은 합성곱 연산을 통해 이미지를 학습함. 이런 방법을 통해 CvT는 토큰에 대한 위치 임베딩을 적용하지 않아도 모델의 성능 저하 없이 다양한 해상도를 가진 이미지를 처리할 수 있게 됨.

## 합성곱 토큰 임베딩(Convolutional Token Embedding)

2D로 재구성된 토큰 맵에서 중첩 합성곱 연산을 수행하는 임베딩을 의미, ViT에 계층적 합성곱 신경망의 성질을 추가하기 위해 사용

기존 트랜스포머 모델은 이미지의 근본적인 2D 모양의 구조를 잃게 됨

CvT 모델은 이미지의 2D 구조를 보존하고 셀프 어텐션을 계산하는 방식, 이미지 패치를 2D 합성곱 임베딩을 사용해 쿼리, 키, 값 임베딩으로 변환해 셀프 어텐션을 계산해 출력을 생성

- 합성곱 기반의 어텐션 임베딩

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/47582e10-34c2-4590-af0c-2f33844172aa/image.png)

3x3 커널 크기, 1 간격의 커널을 적요하면 패치 크기는 3x3으로 생성, 각 쿼리, 키, 벨류

이를 통해 CvT 모델은 지역 특징을 학습하고 시퀀스 길이를 줄이는

## 어탠션에 대한 합성곱 임베딩(Convolutional Projection for Attention)

2D로 재구성된 토큰맵된에서 분리 가능한 합성곱 연산을 적용해 성능 저하 및 계산 복잡도를 낮추는 연산을 의미

일반적으로 쿼리, 키, 값 임베딩은 차원을 동일하게 설정하지만, CvT 모델은 매개변수의 수를 줄이기위해 차원을 축소시킴

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/fed88eae-9a99-4ad3-afee-d1391f5736a5/image.png)

길이가 다른 쿼리(9), 키(4), 값(4)을 사용해도 기존 셀프어텐션의 결과값 사이즈가 9x1로 동일하게 출력될 수 있음

- 이유

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cab23030-666d-4da9-8e8b-fe37a2532f67/89274d64-2d8d-47fd-b458-da64597e46e0/image.png)

(a)에서 9개의 쿼리 패치 임베딩과 4개의 키 패치 임베딩에 대한 중요도를 의미하는 어텐션 맵을 생성, 생성되면 (b)와 같이 값 패치 임베딩을 쿼리 어텐션 맵에 대한 가중치를 반영

셀프 어텐션 벡터를 확인해 보면 입력 벡터와 출력 벡터의 패치 길이가 동일한 것을 확인. 그러므로 계싼해야 하는 이미지 패치가 줄어들어 연산량 감소

CvT모델은 트랜스포머 계층이 깊어질수록 패치 간의 관계를 학습하는 길이를 축소시키는 대신에 벡터의 차원을 증가시켜 모델의 매개변수 수를 대폭 감소시킴

즉 이미지 패치 크기가 줄어든 만큼 임베딩 차원을 늘리는 방법을 택해 네트워크의 안정성을 향상시키고 모델 설계를 단순화함