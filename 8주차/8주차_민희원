# 비전 트랜스포머(601p~659p)
10장 내용을 읽고 정리한 내용입니다.

## ViT (Vision Transformer)
>2020년 구글의 논문을 통해 소개된 이미지 인식을 위한 딥러닝 모델. 이미지를 **자연어 처리 방식처럼 분류**해 보려는 시도에 의해 탄생했다.

이미지 분류 모델에서 사용되는 CNN 모델의 합성곱 계층 방법을 사용하지 않고 트랜스포머 모델에서 사용되는 **셀프 어텐션**을 적용함.

셀프 어텐션을 사용해 전체 이미지를 한 번에 처리하는 방식으로 구현됨.

ViT 모델은 이미지 패치가 왼->오, 상->하 방향(시퀀스 배열)으로 순차적 입력되어 2차원 구조의 이미지 특성을 온전히 반영할 수 없음. -> 이러한 문제 해결하기 위해 물체의 크기나 해상도를 계층적으로 학습하는 **스윈 트랜스포머(Swin Transformer)** 와 **CvT(Convolutional Vision Transformer)** 모델이 제안됨.

### 합성곱 모델과 ViT 모델 비교
합성곱 신경망과 트랜스포머 둘 다 이미지 특징을 잘 표현하는 임베딩을 만들고자 하는 목적은 같지만, 과정에서 큰 차이가 존재.

- **합성곱 신경망(CNN)**: 이미지 처리에 주로 사용되며, 국소적인 연산을 통해 특징을 추출함. 커널(필터)을 사용하여 **국소적인 정보에 집중**하는 방식으로 공간적 계층 구조를 구축함.
- **ViT (Vision Transformer)**: 트랜스포머를 이미지 처리에 적용한 모델. 이미지 전체를 패치(patch) 단위로 나누어, 패치 간의 전역적인 관계를 셀프 어텐션(Self-Attention)으로 학습함. CNN과 달리 국소적인 정보에 집중하는 대신 **전역적인 상관관계를 파악**하는 데 강점이 있음. 더 작은 모델로도 높은 성능을 얻을 수 있다는 장점 존재. 하지만, 패치간의 상대적인 위치 정보만 고려하기에 이미지 변환에 취약할 수 있음.

좁은 수용 영역(Receptive Field, RF)를 가진 합성곱 신경망은 전체 이미지 정보를 표현하는 데 수많은 계층이 필요하지만, **트랜스포머 모델**은 `어텐션 거리`(Attention Distance)를 계산하여 오직 한 개의 ViT 레이어로 전체 이미지 정보를 쉽게 표현할 수 있음.

### ViT의 귀납적 편향
**귀납적 편향**(Inductive Bias)은 일반화 성능 향상을 위한 모델의 가정(Assumption)을 의미.

- **귀납적 편향(Inductive Bias)**: CNN은 국소적으로만 연산하므로, 이미지의 국소적 패턴을 추출하는 데 유리함. 반면, ViT는 이러한 국소적 연산을 사용하지 않기 때문에 특정한 구조적 가정을 가지지 않고 학습함.
- **결과**: ViT는 충분한 데이터와 연산 자원이 있을 때 CNN보다 우수한 성능을 보일 수 있지만, 적은 데이터에서는 CNN에 비해 성능이 낮아질 수 있음.

| 딥러닝 모델 | 귀납적 편향 |
| --- | --- |
| 합성곱 신경망(CNN) | 지역적 편향 |
| 순환 신경망(RNN) | 순차적 편향 |
| ViT | 귀납적 편향이 거의 없음 |


### ViT 모델
- **패치 임베딩(Patch Embedding)**: 이미지를 작은 패치로 분할한 후, 각 패치를 1차원 벡터로 변환. 각 패치는 트랜스포머의 입력으로 사용되며, 이를 통해 이미지 전체의 정보를 학습함.
  
- **인코더 계층(Encoder Layer)**: 트랜스포머의 인코더 구조를 따르며, 각 패치의 정보를 셀프 어텐션(Self-Attention) 메커니즘을 통해 상호작용시킴. 각 계층은 다중 헤드 셀프 어텐션(Multi-Head Self-Attention)과 피드포워드 신경망(Feedforward Neural Network)으로 구성됨.

---

## Swin Transformer
> 2021년 발표한 대규모 비전 인식 모델.

**로컬 윈도(Local Window)** 를 활용해 각 계층의 어텐션이 되는 패치의 크기와 개수를 다양하게 구성해 이미지의 특징을 학습시킴.
로컬 윈도를 활용해 물체의 크기나 해상도를 계층적으로 학습함. 로컬윈도는 스윈 트랜스포머에서 입력 이미지를 처리하기 위해 사용되는 고정 크기의 작은 윈도임.

### ViT와 스윈 트랜스포머 차이
- **ViT**: 패치 단위로 이미지를 처리하며, 이미지 전역의 정보를 셀프 어텐션을 통해 학습함.
- **Swin Transformer**: 전역적 정보 처리가 아닌, **국소적 윈도우(Window) 단위의 어텐션**을 통해 정보를 학습함. 이는 효율성을 높이고, 다양한 해상도에서 작업할 수 있는 장점을 제공.

### Swin Transformer 모델 구조
- **로컬 윈도우(Local Window)**: 이미지를 윈도우 단위로 나누어 국소적으로 어텐션을 계산.
- **이동 윈도우(Shifted Window)**: 한 층에서 계산된 국소 윈도우의 정보를 다음 층에서 약간 이동시켜 어텐션을 계산함으로써, 윈도우 간의 연결을 유도하고 전역적 정보 처리가 가능하게 만듦.
- **다단계(Multi-Stage) 구조**: Swin Transformer는 CNN의 피라미드 구조처럼, 다양한 해상도에서 피처를 추출하는 구조를 사용하여 전역적이며 다층적인 표현을 학습할 수 있음.

---

## CvT (Convolutional Vision Transformer)
기존 합성곱 연산 과정의 ViT에 적용한 모델로, 저수준 특징(Low-level Feature)과 고수준 특징(High-level Feature)을 계층적으로 반영할 수 있음.

예를 들어 사람 얼굴의 저수준 특징은 눈, 코, 입과 같은 작은 단위이며 고수준 특징은 눈, 코, 입을 포함한 전체 얼굴로 비유할 수 있음.

어텐션 연산 과정에서 쿼리(Query, Q), 키(Key, K), 값(Value, V) 중 키와 값을 기존 특징 벡터보다 축소해 계산 복잡도를 감소시킴.

### 합성곱 토큰 임베딩
- CvT는 **Convolutional Token Embedding**을 도입하여, ViT의 패치 임베딩 대신 합성곱을 사용해 더 효율적으로 이미지의 국소적 특징을 추출함. 이는 CNN의 강점을 결합한 방식임.
  
### 어텐션에 대한 합성곱 임베딩
- CvT는 **합성곱 기반의 셀프 어텐션(Convolutional Self-Attention)**을 사용하여, 이미지의 국소적 패턴을 더 잘 포착하면서도 트랜스포머의 전역적인 상관관계 학습 능력을 유지. 이를 통해 이미지 처리의 성능과 효율성을 동시에 개선함.