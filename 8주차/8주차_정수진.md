# 1. Intro

**ViT(Vision Transformer)** : 이미지 인식을 위한 딥러닝 모델

-이미지를 자연어 처리 방식처럼 분류해보려는 시도에 의해 탄생

### 이전과의 차이점

이미지 분류 모델 - CNN모델의 합성곱 계층 방법 : 분류를 위해 지역 특징을 추출

ViT - 트랜스포머 모델의 셀프 어텐션 : 전체 이미지를 한 번에 처리

한계 : 이미지 패치가 순차적으로 입력(왼→오, 위→아래) - 2차원 구조의 이미지 특성을 온전히 반영 X

스윈 트랜스포머(Swin Transformer) & CvT(Convolutional Vision Transformer)

: 물체의 크기나 해상도를 계층적으로 학습함

### Swin Transformer

Local Window를 활용 - 각 계층의 패치의 크기와 개수를 다양하게 구성

이미지 특징을 계층적으로 학습(셀프 어텐션을 로컬 윈도 안, 간 어텐션으로 수행)

-어텐션 함수 → 상대적 위치 편향을 반영(값에 위치적 정보 포함)

### CvT

기존 합성곱 연산 과정을 ViT에 적용 - 저수준 특징(눈코입)과 고수준 특징(전체 얼굴)을 계층적으로 반영 가능

어텐션 연산 과정(쿼리, 키, 값)에서 키와 값을 축소함 → 계산 복잡도 감소

### 실습 내용

데이터 : fashionMNIST

문제: 10개의 카테고리로 상품 분류하기

이미지 인식 진행

# 2. 본론

### ViT

트랜스포머 구조 자체를 컴퓨터비전 분야에 적용한 첫 연구

자연어처리 분야에서 주로 사용함(BERT모델)
